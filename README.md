# ActivationFunctions
Tried implementing activation functions from scratch in Tensorflow.

### Structure
 ```  
src
|
|-- Activations.ipynb
|-- utils
      |-- Utils.ipynb
      |-- utils.py
      
references
|
|--Ref1
|--Refn

```
### Implemented activations:
 
- LeakyReLu
- ParametricReLu
- Elu
- SElu
- GELU

###  Usage
 ``` 
 git clone  https://github.com/Agrover112/ActivationFunctions.git
 or
 zip
```
